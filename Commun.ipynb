{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YovliDuvshani/RideHailling/blob/main/Commun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ethDzezC7Vyb"
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "\n",
        "#!pip install pyhailing\n",
        "#!pip install --upgrade Pillow # Restart runtime\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy\n",
        "import numpy as np #To improve\n",
        "import pyhailing\n",
        "from pyhailing import RidehailEnv\n",
        "import tqdm\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import time as t\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "numpy.random.seed(0)\n",
        "device = torch.device(\"cpu\") #torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te9ytL0gJcIQ"
      },
      "source": [
        "## Distance functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k9WjgWFV7alG"
      },
      "outputs": [],
      "source": [
        "env = RidehailEnv()\n",
        "speeds_data = env.speeds_data.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c4pmwIAS7dN2"
      },
      "outputs": [],
      "source": [
        "def dist_manhattan(list_coord_depart, list_coord_arrivee):\n",
        "  \"\"\" Retourne la distance de Manhattan entre deux points d'un plan \n",
        "  Prend en entrée les coordonnées des points de départ et d'arrivée :\n",
        "  ([x_depart,y_depart],[x_arrivee,y_arrivee]) \"\"\"\n",
        "  \n",
        "  depart = numpy.array(list_coord_depart)\n",
        "  arrivee = numpy.array(list_coord_arrivee)\n",
        "  return numpy.linalg.norm((depart - arrivee), ord=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P6ZuLZir7fAt"
      },
      "outputs": [],
      "source": [
        "def vitesse_normalisee(vitesse_moyenne, sigma):\n",
        "  \"\"\" Retourne un tirage aléatoire d'une loi normale N(vitesse_moyenne,variance_vitesse) \"\"\"\n",
        "  \n",
        "  #return numpy.random.randn(1)*sigma + vitesse_moyenne\n",
        "  loi_normale = numpy.random.randn(1000)\n",
        "  loi_normale = [loi_normale[i]*sigma + vitesse_moyenne for i in range(len(loi_normale))]\n",
        "  limite = numpy.quantile(loi_normale, .10)\n",
        "  normale_tronquee = []\n",
        "  for i in range(len(loi_normale)):\n",
        "    loi_normale[i] = numpy.array(loi_normale[i])[0]\n",
        "    if loi_normale[i] >= limite:\n",
        "      normale_tronquee.append(loi_normale[i])\n",
        "  return random.choices(normale_tronquee)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U0cMbRNH7hIv"
      },
      "outputs": [],
      "source": [
        "def duree_deplacement(list_coord_depart, list_coord_arrivee, time_):\n",
        "  \"\"\" Retourne la duree d'un trajet en secondes\n",
        "  Prend en entrée les coordonnées des points de départ et d'arrivée ainsi que l'heure :\n",
        "  ([x_depart,y_depart],[x_arrivee,y_arrivee],time) \"\"\"\n",
        "\n",
        "  distance = dist_manhattan(list_coord_depart, list_coord_arrivee)\n",
        "  depart = numpy.array(list_coord_depart)\n",
        "  arrivee = numpy.array(list_coord_arrivee)\n",
        "  zone_depart = env.xy_to_zone(depart)\n",
        "  zone_arrivee = env.xy_to_zone(arrivee)\n",
        "  tranche_horaire = int(time_/15/60)*15\n",
        "  vitesse_moyenne = speeds_data[(speeds_data['puzone']==zone_depart) & (speeds_data['dozone']==zone_arrivee) & (speeds_data['min']==tranche_horaire)]['speed_mean']\n",
        "  sigma = speeds_data[(speeds_data['puzone']==zone_depart) & (speeds_data['dozone']==zone_arrivee) & (speeds_data['min']==tranche_horaire)]['speed_stddev']\n",
        "  #vitesse_associee = vitesse_normalisee(vitesse_moyenne, sigma) #WAY TO MUCH TIME TO PROCESS\n",
        "  temps = distance/vitesse_moyenne\n",
        "  return numpy.array(temps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fYS9VNmLQ3UE"
      },
      "outputs": [],
      "source": [
        "def distance_to_request(car_coord, req_coord, car_job, time, first_job_coord, second_job_coord, third_job_coord): #A revoir + Prendre en compte les plages horaires. #Vérifier sur exemple.\n",
        "  \"\"\"\n",
        "  Return the distance to a request taking into account the jobs of the cars. #Distance -> Time\n",
        "  \"\"\"\n",
        "\n",
        "  car_job = str(car_job[0]) + str(car_job[1]) + str(car_job[2])\n",
        "  if car_job in ['044','444','104']: \n",
        "    return duree_deplacement(car_coord,req_coord,time)\n",
        "  if car_job in ['344']:\n",
        "    duree = duree_deplacement(car_coord,first_job_coord[1],time)\n",
        "    duree += duree_deplacement(first_job_coord[1],req_coord,(time+duree)%86400)\n",
        "    return duree\n",
        "  if car_job == '234':\n",
        "    duree = duree_deplacement(car_coord,first_job_coord[1],time) \n",
        "    duree += duree_deplacement(first_job_coord[1],second_job_coord[0],(time+duree)%86400)\n",
        "    duree += duree_deplacement(second_job_coord[0],second_job_coord[1],(time+duree)%86400)\n",
        "    duree += duree_deplacement(second_job_coord[1],req_coord,(time+duree)%86400)\n",
        "    return duree\n",
        "  duree = duree_deplacement(car_coord,first_job_coord[1],time) \n",
        "  duree += duree_deplacement(first_job_coord[1],second_job_coord[0],(time+duree)%86400)\n",
        "  duree += duree_deplacement(second_job_coord[0],second_job_coord[1],(time+duree)%86400)\n",
        "  duree += duree_deplacement(second_job_coord[1],third_job_coord[0],(time+duree)%86400)\n",
        "  duree += duree_deplacement(third_job_coord[0],third_job_coord[1],(time+duree)%86400)\n",
        "  duree += duree_deplacement(third_job_coord[1],req_coord,(time+duree)%86400)\n",
        "  return duree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbSmoP09Jofr"
      },
      "source": [
        "## Heuristic functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7TknLUQ1J3FQ"
      },
      "outputs": [],
      "source": [
        "def plus_proche_lot(coords_voiture, time):\n",
        "  \"\"\" Retourne l'indice du lot le plus proche, prend en entrée la liste des coordonnées du véhicule d'intérêt\n",
        "  [x,y] et l'heure \n",
        "  \"\"\"\n",
        "  lots = numpy.array(env.lots)\n",
        "  durees = []\n",
        "  for i in range(len(lots)):\n",
        "    durees.append(duree_deplacement(coords_voiture, lots[i], time)[0])\n",
        "  return np.argmin(durees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7bij2Yk_J5Ed"
      },
      "outputs": [],
      "source": [
        "def heuristic(state):\n",
        "  \"\"\"\n",
        "  Returns the reposition according to the heuristic used.\n",
        "  \"\"\"\n",
        "  triplets = triplets_jobs(state)\n",
        "  reposition = [env.num_lots]*env.num_vehicles \n",
        "  if len(triplets['444']) > 0:\n",
        "    for i in range(len(triplets['444'])):\n",
        "      lot = plus_proche_lot(state['v_locs'][triplets['444'][i]], state['time'])\n",
        "      reposition[triplets['444'][i]] = lot\n",
        "  return np.array(reposition) #Créer l'array direct : improve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trips_data = env.trips_data"
      ],
      "metadata": {
        "id": "NHwYpboPV1rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tab = np.zeros(len(env.lots['x']))\n",
        "for i,(x,y) in enumerate(zip(env.lots['x'],env.lots['y'])):\n",
        "  tab[i] = env.xy_to_zone(np.array([x,y]))\n",
        "print(f'Nb_zones with iddling spots: {len(np.unique(tab))}')\n",
        "print(f'Nb_zones: {env.num_zones}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMCArfULcW6S",
        "outputId": "b5866a65-e93a-4bcf-ea9a-1feb2495a948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nb_zones with iddling spots: 50\n",
            "Nb_zones: 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Echantillonnage pour définition du milieu des zones\n",
        "\n",
        "res = []\n",
        "x_sampling = np.linspace(env.x_range[0],env.x_range[1],1000)\n",
        "y_sampling = np.linspace(env.y_range[0],env.y_range[1],1000)\n",
        "\n",
        "for x in x_sampling:\n",
        "  for y in y_sampling:\n",
        "    res += [[x,y,env.xy_to_zone(np.array([x,y]))]]"
      ],
      "metadata": {
        "id": "cfzUEFx6fWee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_ = np.array(res)\n",
        "res_ord = pd.DataFrame(data = res_,columns=['x','y','zone'])"
      ],
      "metadata": {
        "id": "cTRoXXecgpJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_ord[res_ord['zone']==13]['x'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7X8Wn3zg688",
        "outputId": "1252e756-6d67-4ca4-e754-383c793184c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "586.4925185091538"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process global (intéréssant à calculer : durée de déplacement médiane d'un trajet et moyenne + nb_requests en fct du créneau du jour)\n",
        "\n",
        "# Définir un centre pour chaque zone (échantillonnage)\n",
        "# Pré-process : Pour chaque zone et chaque timestep -> définir les zones atteignables (en bonus : plusieurs seuils, par exemple 3,4,5 minutes) + Gérer les zones n'ayant pas de lots proches(par exemple -> les enlevés).\n",
        "# Recherche Optimum Global ou Heuristique (plusieurs optimums potentiellement) -> Maximiser le fait de ne pas rater de requêtes (prendre en compte les véhicules bientot disponibles)\n",
        "# Prendre en compte les distances des véhicules aux locations pour à la fois que cette distance ne soit pas élevé mais aussi que les zones soit atteignables par ces véhicules \n",
        "#avant que l'on pense avoir des requêtes.(le nb de véhicules se relocalisant déjà, etc...)\n"
      ],
      "metadata": {
        "id": "GAhzOZEiYNTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxf3P9NmWU-D"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2yl4W71FJ14L"
      },
      "outputs": [],
      "source": [
        "def triplets_jobs(state): #Statut\n",
        "  \"\"\" Prend en entrée l'état de l'environnement et retourne les listes des indices des véhicules pour chaque\n",
        "  triplet de jobs sous forme d'une liste de listes ayant chaucune le triplet en premier élément \n",
        "  \"\"\"\n",
        "  jobs = state['v_jobs']\n",
        "  dic = {'044':[],'104':[],'234':[],'323':[],'344':[],'444':[]}\n",
        "  for i in range(len(jobs)):\n",
        "    triplet = str(jobs[i][0]) + str(jobs[i][1]) + str(jobs[i][2])\n",
        "    dic[triplet] += [i]\n",
        "  return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Q2DNLMUIWf8R"
      },
      "outputs": [],
      "source": [
        "# Coordonate normalization\n",
        "estimated_mean_x = 587.89\n",
        "estimated_sigma_x = 0.94\n",
        "estimated_mean_y = 4512.1\n",
        "estimated_sigma_y = 3.21\n",
        "def normalize_x(x):\n",
        "  return (x-estimated_mean_x)/estimated_sigma_x\n",
        "def normalize_y(y):\n",
        "  return (y-estimated_mean_y)/estimated_sigma_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCDN3XuWKx1T"
      },
      "source": [
        "## Q learning algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4trOxLIjAsBq"
      },
      "outputs": [],
      "source": [
        "# Memory\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size, device):\n",
        "        self.max_size = max_size\n",
        "        self.mem_cntr = 0\n",
        "\n",
        "        self.state_cars_memory = [] #Precise\n",
        "        self.state_global_memory = [] \n",
        "        self.new_state_cars_memory = [] \n",
        "        self.new_state_global_memory = []\n",
        "        self.new_state_jobs_memory = []\n",
        "        self.action_memory = [] #Consider action going from 0 to nb_car // Size : self.mem_size*nb_actions_to_make_in_state(it varies)\n",
        "        self.timelapse_memory = []\n",
        "\n",
        "        self.terminal_memory = [] #We could use arrays here\n",
        "        self.reward_memory = [] #We could use arrays here\n",
        "        self.device = device\n",
        "\n",
        "    def push(self, state_cars, state_global, action, reward, new_state_cars, new_state_global, new_state_jobs, timelapse, done):\n",
        "        \"\"\"\n",
        "        Add a new sample and replace oldest one if full\n",
        "        \"\"\"\n",
        "        self.state_cars_memory += [state_cars]\n",
        "        self.state_global_memory += [state_global]\n",
        "        self.new_state_cars_memory += [new_state_cars]\n",
        "        self.new_state_global_memory += [new_state_global]\n",
        "        self.action_memory += [action]\n",
        "        self.reward_memory += [reward]\n",
        "        self.new_state_jobs_memory += [new_state_jobs]\n",
        "        self.timelapse_memory += [timelapse]\n",
        "        self.terminal_memory += [done]\n",
        "\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "        # Supress 1st element if too many of them.\n",
        "        if self.mem_cntr>self.max_size:\n",
        "          self.state_cars_memory.pop(0)\n",
        "          self.state_global_memory.pop(0)\n",
        "          self.new_state_cars_memory.pop(0)\n",
        "          self.new_state_global_memory.pop(0)\n",
        "          self.action_memory.pop(0)\n",
        "          self.reward_memory.pop(0)\n",
        "          self.new_state_jobs_memory.pop(0)\n",
        "          self.timelapse_memory.pop(0)\n",
        "          self.terminal_memory.pop(0)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"\n",
        "        Sample from the memory\n",
        "        return : list of size 'batch_size' containing different observations.\n",
        "        \"\"\"\n",
        "        max_mem = min(self.mem_cntr, self.max_size)\n",
        "        batch = np.random.choice(max_mem, batch_size, replace=False) #It's probably not gonna work that way.\n",
        "\n",
        "        states_cars = []\n",
        "        states_global = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        new_states_cars = []\n",
        "        new_states_global = []\n",
        "        new_state_jobs = []\n",
        "        terminal = []\n",
        "        timelapse = []\n",
        "        for ele in batch:\n",
        "          states_cars += [self.state_cars_memory[ele]]\n",
        "          states_global += [self.state_global_memory[ele]]\n",
        "          actions += [self.action_memory[ele]]\n",
        "          rewards += [self.reward_memory[ele]]\n",
        "          new_states_cars += [self.new_state_cars_memory[ele]]\n",
        "          new_states_global += [self.new_state_global_memory[ele]]\n",
        "          new_state_jobs += [self.new_state_jobs_memory[ele]]\n",
        "          terminal += [self.terminal_memory[ele]]\n",
        "          timelapse += [self.timelapse_memory[ele]]\n",
        "\n",
        "        return states_cars, states_global, actions, self.to_torch(rewards), new_states_cars, new_states_global, new_state_jobs, self.to_torch(timelapse), self.to_torch(terminal)\n",
        "\n",
        "    def to_torch(self, x):\n",
        "        return torch.tensor(x).to(self.device)\n",
        "\n",
        "    def to_numpy(self, x):\n",
        "        return x.detach().cpu().numpy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(self.mem_cntr, self.max_size) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WmPDryyPBTy9"
      },
      "outputs": [],
      "source": [
        "# Network\n",
        "\n",
        "class ReqN(nn.Module):\n",
        "    def __init__(self, cars_input_size, global_input_size, nb_car, hidden_size_1=10,hidden_size_2=500):\n",
        "        super().__init__()\n",
        "        self.cars_input = cars_input_size\n",
        "        self.global_input = global_input_size\n",
        "        self.nb_car = nb_car\n",
        "        self.linear_1 = nn.Linear(cars_input_size, hidden_size_1)\n",
        "        self.linear_2 = nn.Linear(hidden_size_1, hidden_size_1)\n",
        "        self.linear_3 = nn.Linear(hidden_size_1*nb_car+global_input_size, hidden_size_2)\n",
        "        self.linear_4 = nn.Linear(hidden_size_2, hidden_size_2)\n",
        "        self.linear_5 = nn.Linear(hidden_size_2, nb_car+1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, y): #x : batch_size*(Nb_car)*x_input  ; y : batch_size*(nb_caracteristics_global : y_input)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        x = torch.cat((x,y),1)\n",
        "\n",
        "        x = self.linear_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear_4(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        output = self.linear_5(x)\n",
        "        if output.shape[0]==1:\n",
        "          x = x.squeeze(0)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6d5JZUsQBYus"
      },
      "outputs": [],
      "source": [
        "# Agent\n",
        "\n",
        "class Agent(object):\n",
        "\n",
        "    def __init__(self, \n",
        "                 n_actions,\n",
        "                 memory, \n",
        "                 eps, eps_decay,\n",
        "                 discount_rate, \n",
        "                 update_delay, \n",
        "                 device\n",
        "                 ):\n",
        "        \n",
        "        self.action_space = [i for i in range(n_actions)] #n_actions = nb of cars + 1 (it's not possible to refuse an action)\n",
        "        self.memory = memory \n",
        "        self.eps, self.eps_decay = eps, eps_decay\n",
        "        self.discount_rate = discount_rate #Should be equal to 1 at some point!!\n",
        "        self.update_delay = update_delay\n",
        "        self.counter = 0\n",
        "        self.device = device\n",
        "\n",
        "        self.requests_repository = pd.DataFrame(columns=['time','day']) #Easier to store these values into a dataframe / Allows to have information on the lasts requests.\n",
        "\n",
        "    def init_nets(self, Q_net, target_net, optimizer, batch_size):\n",
        "        \"\"\"\n",
        "        initialize online and targets\n",
        "        \"\"\"\n",
        "        self.Q_net = Q_net\n",
        "        self.target_net = target_net\n",
        "        self.optimizer = optimizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.cars_input = self.Q_net.cars_input \n",
        "        self.global_input = self.Q_net.global_input\n",
        "        self.nb_car = self.Q_net.nb_car\n",
        "\n",
        "        self.copy_weights()\n",
        "        self.counter += 1\n",
        "    \n",
        "    def to_torch(self, x):\n",
        "        return torch.tensor(x).to(self.device).float()\n",
        "\n",
        "    def to_numpy(self, x):\n",
        "        return x.detach().cpu().numpy()\n",
        "\n",
        "    def create_mask(self, jobs, state_tensor_cars, state_tensor_global, time_max=250): \n",
        "      \"\"\"\n",
        "      Create a mask for the car that we cannot assign to a certain request and that for every request of a state.\n",
        "      return: a list of 0 and 1 where 1 means that we mask the outcome, size: nb_request*(nb_car+1)\n",
        "      \"\"\"\n",
        "      # Deal with cars, for which the distance is too high.\n",
        "      nb_request = state_tensor_cars.shape[0]\n",
        "      time = state_tensor_global[0][1]\n",
        "      mask = torch.zeros(nb_request,self.nb_car+1).to(self.device)\n",
        "      for i in range(nb_request):\n",
        "        request_time = state_tensor_global[i][2]\n",
        "        for j in range(self.nb_car):\n",
        "          mask[i][j] = (time_max - state_tensor_cars[i][j][2] + request_time - time) < 0 #if not accesible then 1.\n",
        "\n",
        "      # Deal with cars which already have too many jobs\n",
        "      for car in (jobs['323']+jobs['234']):\n",
        "        for i in range(nb_request):\n",
        "          mask[i,car] = 1 \n",
        "      return mask\n",
        "\n",
        "    def train(self, states_cars, states_global, targets, mask, list_association):\n",
        "        \"\"\"\n",
        "        Train online net for 1 step\n",
        "        \"\"\"\n",
        "        self.optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        self.Q_net.train()\n",
        "        Q_values = self.Q_net(states_cars,states_global).to(device) #nb_reqs(in the whole batch) *nb_actions \n",
        "\n",
        "        # Masking\n",
        "        Q_values = (Q_values*mask).sum(-1)\n",
        "\n",
        "        # Aggregate\n",
        "        aggreg_link = self.aggregation_link(Q_values, list_association)\n",
        "        Q_values = torch.transpose(aggreg_link,0,1) @ Q_values #batch_size*nb_actions\n",
        "\n",
        "        # Computing loss\n",
        "        loss = (targets.detach() - Q_values).pow(2).mean()\n",
        "        loss.backward()\n",
        "        \n",
        "        # Apply gradients\n",
        "        self.optimizer.step()\n",
        "        self.Q_net.eval()\n",
        "\n",
        "    def copy_weights(self):\n",
        "        \"\"\"\n",
        "        Copy weights from online to target net\n",
        "        \"\"\"\n",
        "        self.target_net.load_state_dict(self.Q_net.state_dict())\n",
        "\n",
        "    def select_action(self, states_cars, states_global, mask): #Optimize it by taking the action : no assignement (in the beggining) very frequently.\n",
        "        \"\"\"\n",
        "        Select an action with eps greedy as well as dealing with the overlapping issue\n",
        "        \"\"\"\n",
        "        # Epsilon greedy\n",
        "\n",
        "        list_action = []\n",
        "        for i,(state_cars,state_global) in enumerate(zip(states_cars,states_global)):\n",
        "          rand = np.random.random()\n",
        "          if rand < self.eps: #If we choose randomly\n",
        "            action = np.random.choice(self.action_space) \n",
        "            while (action in list_action or mask[i][action]==1) and action != self.nb_car: #Continue until we find an action we can realize. \n",
        "              action = np.random.choice(self.action_space)\n",
        "            list_action += [action]\n",
        "          else: #If we take the max Q value\n",
        "            tensor_action = self.Q_net(state_cars.unsqueeze(0),state_global.unsqueeze(0)).to(self.device)\n",
        "            tensor_action.masked_fill_(mask[i],-np.inf) #Other formulation : tensor_action += tensor_action*mask[i]*(-100000\n",
        "            action = self.to_numpy(torch.max(tensor_action,1)[1])[0]\n",
        "            # Deal with overlapping actions : 1st arrived 1st served.\n",
        "            k = 2\n",
        "            while (action.item() in list_action or mask[i,action]==1) and action.item() != self.nb_car: #Continue until we find an action we can realize.\n",
        "              action = self.to_numpy(torch.topk(tensor_action.squeeze(0),k)[1][k-1])\n",
        "              k += 1\n",
        "            list_action += [action]\n",
        "                                          \n",
        "        return np.array(list_action) #To improve: we don't need to create a list\n",
        "\n",
        "    def remember(self, *args):\n",
        "        \"\"\"\n",
        "        Update memory\n",
        "        args: state_cars, state_global, action, reward, new_state_cars, new_state_global, new_state_jobs, timelapses, done\n",
        "        \"\"\"\n",
        "\n",
        "        self.memory.push(*args)\n",
        "\n",
        "    def regroup_tensor(self, states_cars, states_global):\n",
        "      \"\"\"\n",
        "      Regroup tensors stored into a list into a unique tensor\n",
        "      return : a unique tensor composed of every input tensors with a list which associates the input with the output\n",
        "      \"\"\"\n",
        "      # Create an association list between the elements of this batch and compute the total amount of request in this batch.\n",
        "      n_element = 0\n",
        "      list_association = []\n",
        "\n",
        "      for i,(state_cars,state_global) in enumerate(zip(states_cars,states_global)):\n",
        "        n_element += len(state_cars)\n",
        "        for j in range(len(state_cars)):\n",
        "          list_association += [[i,j]]\n",
        "      \n",
        "      # Fill the tensors we're going to use for the batch\n",
        "      states_cars_ = torch.zeros(n_element,self.nb_car,self.cars_input).to(device)\n",
        "      states_global_ = torch.zeros(n_element,self.global_input).to(device)\n",
        "\n",
        "      count = 0\n",
        "      for i,(state_cars,state_global) in enumerate(zip(states_cars,states_global)):\n",
        "        for j in range(len(state_cars)):\n",
        "          states_cars_[count] = state_cars[j]\n",
        "          states_global_[count] = state_global[j]\n",
        "          count += 1\n",
        "\n",
        "      return states_cars_,states_global_,list_association\n",
        "\n",
        "    def requests_repository_update(self,state):\n",
        "      \"\"\"\n",
        "      Update the requests_repository with the current timestep.\n",
        "      \"\"\"\n",
        "      time = state['time']\n",
        "      day = state['dow']\n",
        "      for req_time in state['request_times']:\n",
        "        if req_time == time:\n",
        "          self.requests_repository = self.requests_repository.append({'time': time,'day': day},ignore_index=True)\n",
        "      self.requests_repository_filter(time,day)\n",
        "\n",
        "    def requests_repository_filter(self,time,day,lim = 900):\n",
        "      self.requests_repository = self.requests_repository[(self.requests_repository['time']>time-900) & (self.requests_repository['day']==day)]\n",
        "\n",
        "    def dict_to_network(self,state):\n",
        "      \"\"\"\n",
        "      Takes (in input) the state dict and transforms it into a tensor while selecting the right features.\n",
        "      \"\"\"\n",
        "      # Build tensors 'cars' and 'global'.\n",
        "      n = len(state['request_times'])\n",
        "      cars_input = torch.zeros(n,self.nb_car,self.cars_input).to(self.device)\n",
        "      global_input = torch.zeros(n,self.global_input).to(self.device)\n",
        "      for i in range(n):\n",
        "        for car in range(self.nb_car):\n",
        "          cars_input[i][car][0] = normalize_x(state['v_locs'][car][0])\n",
        "          cars_input[i][car][1] = normalize_y(state['v_locs'][car][1])\n",
        "          # Calculate the distance to the request.\n",
        "          first_job_coord = state['v_job_locs'][car][0] #We retrieve it even if it's not necessary\n",
        "          second_job_coord = state['v_job_locs'][car][1] \n",
        "          third_job_coord = state['v_job_locs'][car][2]\n",
        "          cars_input[i][car][2] = self.to_torch(distance_to_request(state['v_locs'][car], state['request_locs'][i][0], state['v_jobs'][car], state['time'], first_job_coord, second_job_coord, third_job_coord))\n",
        "        global_input[i][0:5] = torch.Tensor(np.array([i==state['dow'] for i in range(5)])) #day / one_hot encode\n",
        "        global_input[i][5] = state['time'] #Projeté dans un espace latent le time? \n",
        "        global_input[i][6] = state['request_times'][i] \n",
        "        # Amount of available cars (right away)\n",
        "        jobs = triplets_jobs(state) #Could add it to the argument of the function\n",
        "        global_input[i][7] = len(jobs['044']) + len(jobs['104']) + len(jobs['444'])  \n",
        "        # Amount of requests\n",
        "        global_input[i][8] = len(state['request_times'])\n",
        "        # Amount of requests in the last 15 mins.\n",
        "        global_input[i][9] = len(self.requests_repository['time'])\n",
        "        # Requests coordinate\n",
        "        global_input[i][10] = normalize_x(state['request_locs'][i][0][0]) #The place where we take the request : x coord\n",
        "        global_input[i][11] = normalize_y(state['request_locs'][i][0][1]) #The place where we take the request : y coord\n",
        "      return cars_input,global_input\n",
        "\n",
        "    def action_to_tensor(self, actions):\n",
        "      \"\"\"\n",
        "      Transforms the list of actions of a batch into a single tensor.\n",
        "      \"\"\"\n",
        "      list_res = []\n",
        "      for list_action in actions:\n",
        "        for action in list_action:\n",
        "          list_res += [action]\n",
        "      return self.to_torch(np.array(list_res))\n",
        "    \n",
        "    def aggregation_link(self, Q_values, list_association):\n",
        "      \"\"\"\n",
        "      Create a matrix of size : nb_requests(in the batch) * batch_size, \n",
        "      \"\"\"\n",
        "      mask = torch.zeros(Q_values.shape[0],self.batch_size).to(device) #Nb_reqs * batch_size \n",
        "      count = 0\n",
        "      for j in range(self.batch_size):\n",
        "        temp = []\n",
        "        for pair in list_association:\n",
        "          if pair[0] == j:\n",
        "            temp += [count]\n",
        "            count += 1\n",
        "        for i in temp:\n",
        "          mask[i][j] = 1/len(temp)\n",
        "      return mask\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Apply deep Q-learning algorithm step\n",
        "        \"\"\"\n",
        "        if len(self.memory) >= self.batch_size:\n",
        "\n",
        "            # Sample from memory\n",
        "            states_cars, states_global, actions, reward, new_states_cars, new_states_global, new_states_jobs, timelapses,done = self.memory.sample(self.batch_size) \n",
        "\n",
        "            # Compute the mask(action) on every element of the batch for new_state       \n",
        "            actions_new_state = []\n",
        "            for ele_cars,ele_global,ele_jobs in zip(new_states_cars,new_states_global,new_states_jobs):\n",
        "              mask = self.create_mask(ele_jobs,ele_cars,ele_global)\n",
        "              actions_new_state += [self.select_action(ele_cars,ele_global,mask)] #SARSA\n",
        "            actions_new_state = self.action_to_tensor(actions_new_state)\n",
        "            mask = F.one_hot(actions_new_state.long(),num_classes=21)\n",
        "\n",
        "            # Regroup the states and compute the association lists\n",
        "            states_cars, states_global, list_association = self.regroup_tensor(states_cars, states_global)\n",
        "            new_states_cars, new_states_global, new_list_association = self.regroup_tensor(new_states_cars, new_states_global)\n",
        "\n",
        "            # Compute target Q value\n",
        "            target_Q_value = self.target_net(new_states_cars,new_states_global)\n",
        "\n",
        "            # We 'add' the mask\n",
        "            target_Q_value = (target_Q_value*mask).sum(-1)\n",
        "\n",
        "            # Agglomerate the different Q_value\n",
        "            aggreg_link = self.aggregation_link(target_Q_value,new_list_association)\n",
        "            Agglomerate_Q_value = torch.transpose(aggreg_link,0,1) @ target_Q_value \n",
        "\n",
        "            # Compute target\n",
        "            target_Q_value = reward + torch.pow(self.discount_rate*torch.ones(self.batch_size),timelapse/60).to(device)*Agglomerate_Q_value*done.to(device)  \n",
        "\n",
        "            # Change actions into usable tensors\n",
        "            actions = self.action_to_tensor(actions)\n",
        "\n",
        "            # Compute mask for actions\n",
        "            mask = F.one_hot(actions.long(),num_classes=21)\n",
        "\n",
        "            # Train network         \n",
        "            self.train(states_cars, states_global, target_Q_value, mask, list_association)\n",
        "\n",
        "            # Copy weights\n",
        "            if self.counter % self.update_delay == 0:\n",
        "                self.copy_weights()\n",
        "\n",
        "            # Update epsilon\n",
        "            self.eps *= self.eps_decay\n",
        "\n",
        "            self.counter += 1\n",
        "        else:\n",
        "            return\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6a7rW79NdLqT",
        "outputId": "f915ece9-428b-4969-ead5-c4d15bfcd5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([15])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 224.29111309871996\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 484.9911660731291\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([19, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 488.7343229001261\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([17])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 1164.855381674763\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 1286.1023087517056\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302,  22])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 1512.6711578905285\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 2275.854765532202\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([16,  9])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 2512.2328245689782\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([15])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3310.4169614442076\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([5])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3609.5891172410124\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3615.6367384728255\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([17])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3943.576221714786\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([14])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 4303.121605854023\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([11])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 4768.66515640354\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([0])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 5447.141271005511\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 5687.833608211517\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 5851.6870929914385\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 7035.825492758854\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20,  1])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 7252.508285530079\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([0])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 7401.4466988465565\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([15])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 8056.1515212802215\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 8247.222540989042\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 9038.815113823015\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 9773.632299784724\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([10])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 11206.906657076785\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([4])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 11710.880263724146\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 11912.726813210715\n",
            "Running...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:39<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-fdf55314f6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Apply Heuristic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0maction_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Select action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6cfa4ff3ab55>\u001b[0m in \u001b[0;36mheuristic\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'444'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'444'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mlot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplus_proche_lot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v_locs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'444'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mreposition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'444'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreposition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Créer l'array direct : improve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-73ddd00e7b78>\u001b[0m in \u001b[0;36mplus_proche_lot\u001b[0;34m(coords_voiture, time)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdurees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdurees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduree_deplacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords_voiture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdurees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-90c310b4d831>\u001b[0m in \u001b[0;36mduree_deplacement\u001b[0;34m(list_coord_depart, list_coord_arrivee, time_)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtranche_horaire\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mvitesse_moyenne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'puzone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mzone_depart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dozone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mzone_arrivee\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtranche_horaire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speed_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'puzone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mzone_depart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dozone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mzone_arrivee\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspeeds_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtranche_horaire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speed_stddev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;31m#vitesse_associee = vitesse_normalisee(vitesse_moyenne, sigma) #WAY TO MUCH TIME TO PROCESS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtemps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvitesse_moyenne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;34mf\"a_value {op_str} b_value\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mlocal_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"a_value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b_value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"safe\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         )\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0m_numexpr_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompiled_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mevaluate_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "\n",
        "env = RidehailEnv()\n",
        "\n",
        "MEMORY_SIZE = 10000\n",
        "CARS_INPUT_SIZE = 3\n",
        "GLOBAL_INPUT_SIZE = 12\n",
        "N_CAR = env.num_vehicles\n",
        "\n",
        "LR = 0.001\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "N_SIMULATION = 10\n",
        "EPS = 0.9\n",
        "EPS_DECAY = 0.9995\n",
        "DISCOUNT_RATE = 0.99 # should depend of t\n",
        "UPDATE_DELAY = 50 # delay between target_net parameters updates\n",
        "DEVICE = \"cpu\" # \"cuda\" or \"cpu\"\n",
        "\n",
        "# Model and target model \n",
        "Q_net = ReqN(CARS_INPUT_SIZE, GLOBAL_INPUT_SIZE, N_CAR).to(DEVICE)\n",
        "target_net = ReqN(CARS_INPUT_SIZE, GLOBAL_INPUT_SIZE, N_CAR).to(DEVICE)\n",
        "\n",
        "# Optimizer (only on Q_net)\n",
        "optimizer = torch.optim.Adam(Q_net.parameters(), lr=LR)\n",
        "\n",
        "# Memory\n",
        "memory = ReplayBuffer(MEMORY_SIZE, DEVICE)\n",
        "\n",
        "# Agent and initialization\n",
        "agent = Agent(n_actions=N_CAR+1, \n",
        "              memory=memory, \n",
        "              eps=EPS, \n",
        "              eps_decay=EPS_DECAY,\n",
        "              discount_rate=DISCOUNT_RATE,\n",
        "              update_delay=UPDATE_DELAY, \n",
        "              device=DEVICE\n",
        "              )\n",
        "\n",
        "agent.init_nets(Q_net, target_net, optimizer, BATCH_SIZE)\n",
        "\n",
        "all_scores = []\n",
        "# Progress bar\n",
        "with tqdm.tqdm(total=N_SIMULATION, position=0, leave=True) as pbar:\n",
        "    for i in range(N_SIMULATION):\n",
        "        done = False\n",
        "        score = 0\n",
        "        # Reset env\n",
        "        state = env.reset()\n",
        "\n",
        "        # Make sure that the first state is a state with request\n",
        "        while len(state['request_times']) == 0:\n",
        "          action_rep = heuristic(state)\n",
        "          action = {'reposition': action_rep, 'req_assgts': np.array([]), 'req_rejections': np.array([])}\n",
        "          state, reward, _, _ = env.step(action)\n",
        "          score += reward\n",
        "\n",
        "        #Store the states in a list for the analysis.\n",
        "        list_state = []\n",
        "        list_state += [state]\n",
        "        state_tensor_cars,state_tensor_global = agent.dict_to_network(state)\n",
        "\n",
        "        # Update request repositories\n",
        "        agent.requests_repository_update(state)\n",
        "\n",
        "        while not done:\n",
        "            print('Running...')\n",
        "            # Retrieve lists of triplets from state\n",
        "            jobs = triplets_jobs(state)\n",
        "\n",
        "            # Create the mask for every request (taking into account the distance)\n",
        "            mask = agent.create_mask(jobs,state_tensor_cars,state_tensor_global)\n",
        "\n",
        "            # Apply Heuristic\n",
        "            action_rep = heuristic(state)\n",
        "\n",
        "            # Select action\n",
        "            action_req = agent.select_action(state_tensor_cars,state_tensor_global, mask)\n",
        "\n",
        "            # Construct action # A not so probable error to correct : if request assign at the same time that a reposition is requested : gotta change the status!!!\n",
        "            action = OrderedDict({'reposition': action_rep, 'req_assgts': action_req, 'req_rejections': np.zeros_like(action_req)}) #Need to deal with the rejections probably #May need to be an ordered dict\n",
        "\n",
        "            # Print the action realised during this round\n",
        "            print('Action:', action)\n",
        "            day = state['dow']\n",
        "            time = state['time']\n",
        "            print(f'day : {day}/ time : {time}')\n",
        "\n",
        "            # Execute action\n",
        "            new_state, reward, done, _ = env.step(action) #Should compute the mean reward.\n",
        "              \n",
        "            # While no request for new_state : Apply heuristic and create a new action / There may be a problem with done.\n",
        "            while len(new_state['request_times']) == 0 and not done:\n",
        "              action_rep = heuristic(new_state)\n",
        "              action = {'reposition': action_rep, 'req_assgts': np.array([]), 'req_rejections': np.array([])}\n",
        "              new_state, reward_add, done, _ = env.step(action)\n",
        "              reward += reward_add\n",
        "              \n",
        "            score += reward\n",
        "            if not done: #to deal with the end of the environnment in the case that it happens during the while loop.\n",
        "              # Update request repositories\n",
        "              agent.requests_repository_update(new_state)\n",
        "\n",
        "              # Transforms state into a usable tensor for the : request network\n",
        "              new_state_tensor_cars,new_state_tensor_global = agent.dict_to_network(new_state)\n",
        "\n",
        "              # Update memory\n",
        "              new_jobs = triplets_jobs(new_state)\n",
        "              timelapse = new_state['time'] - state['time']\n",
        "              agent.remember(state_tensor_cars,state_tensor_global, action_req, reward, new_state_tensor_cars, new_state_tensor_global, new_jobs, timelapse,1-int(done))\n",
        "\n",
        "              # Apply algorithm\n",
        "              for i in range(1):\n",
        "                agent.step() #We should maybe iterate to apply the step more often.\n",
        "\n",
        "              # Update state\n",
        "              state = new_state\n",
        "              list_state += [state]\n",
        "              state_tensor_cars,state_tensor_global = new_state_tensor_cars,new_state_tensor_global\n",
        "        \n",
        "        all_scores.append(score)\n",
        "\n",
        "        pbar.set_description('score=' + str(score))\n",
        "        pbar.update()\n",
        "\n",
        "plt.plot(all_scores)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBCsgdl6vcku"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_RCaI-xnvvY",
        "outputId": "1d82600b-d9ef-42af-f981-803ac8e7e65a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2880.5767908354665"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OllsBrBzmPYt"
      },
      "outputs": [],
      "source": [
        "state = env.reset()\n",
        "state['dow']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTHpEC9Kbiwi",
        "outputId": "ce6c873a-3919-4686-df01-cd37d9c87cf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([130.49006675])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = list_state[30]['v_locs'][1]\n",
        "v1 = list_state[30]['request_locs'][0][0]\n",
        "time = list_state[30]['time']\n",
        "duree_deplacement(v,v1,time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtisxkIlc633"
      },
      "outputs": [],
      "source": [
        "list_state[29]['request_times']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WVzd84hcN_q"
      },
      "outputs": [],
      "source": [
        "list_state[29]['v_jobs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x37r_5Odb_Wf"
      },
      "outputs": [],
      "source": [
        "list_state[6]['v_jobs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeVrJhkETcgo"
      },
      "outputs": [],
      "source": [
        "v = new_state['v_locs'][0]\n",
        "time = new_state['time']\n",
        "v1 = np.array(env.lots)[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fch1_98mTwu4"
      },
      "outputs": [],
      "source": [
        "v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMIKe-lQRkqm"
      },
      "outputs": [],
      "source": [
        "heuristic(new_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7h9kBcAZdtQ"
      },
      "outputs": [],
      "source": [
        "action = env.get_random_action()\n",
        "action "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWnpsWN8-N2P"
      },
      "outputs": [],
      "source": [
        "OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
        "       302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Te9ytL0gJcIQ",
        "hbSmoP09Jofr",
        "sxf3P9NmWU-D",
        "CBCsgdl6vcku"
      ],
      "name": "Commun",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}