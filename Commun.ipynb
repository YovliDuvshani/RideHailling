{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commun",
      "provenance": [],
      "collapsed_sections": [
        "hbSmoP09Jofr",
        "CBCsgdl6vcku"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pistes : \n",
        "\n",
        "* Probabilité de faire attendre une requête élevée puis diminue à chaque attente : réinitialisée quand assignation plutôt que attente choisie; coef entre 0 et 1 de multiplication de cette probabilité à la puissance nombre d'assignations\n",
        "* Découpage en epochs de période constante (=batching) : expression de la reward temporelle facile ==> problème = déclenchement d'une epoch pour une nouvelle requête donc pas nécessairement pile en fin de période\n",
        "* Hot/cold areas : si conflit entre 2 voitures, assigner celle de la cold area, si conflit entre 2 requêtes, assigner celle qui mène dans une hot area\n",
        "* Policy evaluation ?\n",
        "* Métriques : temps moyen d'un trajet pour satisfaire une requête, taux de requêtes satisfaites\n",
        "* Collective greedy policy ?\n",
        "* Améliorer l'heuristique\n",
        "* Grasp metaheuristic ==> heuristic ?\n",
        "* Transformers pour gérer l'interchangeabilité des voitures pour le 1er réseau (attention)\n",
        "* Gérer les conflits de relocalisation : infos globales sur les autres véhicules\n",
        "* Stockage des localisations des requêtes pour filtrage dans une période donnée proche de l'epoch afin de réaliser clustering des hot areas\n",
        "* Réseau de relocalisation qui prend en entrée le temps pour atteindre chaque lot pour chaque voiture, un classement des lots les plus intéressants et des infos sur les autres voitures, et pq pas des infos sur les requêtes précédentes\n",
        "* Entrée du réseau d'assignation de requêtes : coords voiture, temps de trajet jusqu'à requête pour chaque voiture, zone voiture, coords requête, zone requête, time, nb voitures dispos, nb requêtes en attente, nb de requêtes dans les 15 dernières minutes\n",
        "* Si pas de requête au bout d'une minute : repositionnement\n",
        "* Cerebellar embedding ==> Hierarchical hexagon grid system ?\n",
        "* Regulariser descente du gradient avec terme de pénalité (constante Lipschitzienne du réseau) à chaque itération ?\n",
        "* Vitesse normalisée incohérente avec tirage de l'environnement\n",
        "* Autoencoder pour contourner attention\n",
        "\n"
      ],
      "metadata": {
        "id": "WpE7wBEiXglp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ethDzezC7Vyb"
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "\n",
        "#!pip install pyhailing\n",
        "#!pip install --upgrade Pillow # Restart runtime\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy\n",
        "import numpy as np #To improve\n",
        "import pyhailing\n",
        "from pyhailing import RidehailEnv\n",
        "import tqdm\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import time as t\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#seed\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance functions"
      ],
      "metadata": {
        "id": "Te9ytL0gJcIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = RidehailEnv()\n",
        "speeds_data = env.speeds_data.reset_index()"
      ],
      "metadata": {
        "id": "k9WjgWFV7alG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_manhattan(list_coord_depart, list_coord_arrivee):\n",
        "  \"\"\" Retourne la distance de Manhattan entre deux points d'un plan \n",
        "  Prend en entrée les coordonnées des points de départ et d'arrivée :\n",
        "  ([x_depart,y_depart],[x_arrivee,y_arrivee]) \"\"\"\n",
        "  \n",
        "  depart = numpy.array(list_coord_depart)\n",
        "  arrivee = numpy.array(list_coord_arrivee)\n",
        "  return numpy.linalg.norm((depart - arrivee), ord=1)"
      ],
      "metadata": {
        "id": "c4pmwIAS7dN2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vitesse_normalisee(vitesse_moyenne, sigma):\n",
        "  \"\"\" Retourne un tirage aléatoire d'une loi normale N(vitesse_moyenne,variance_vitesse) \"\"\"\n",
        "  \n",
        "  #return numpy.random.randn(1)*sigma + vitesse_moyenne\n",
        "  loi_normale = numpy.random.randn(1000)\n",
        "  loi_normale = [loi_normale[i]*sigma + vitesse_moyenne for i in range(len(loi_normale))]\n",
        "  limite = numpy.quantile(loi_normale, .10)\n",
        "  normale_tronquee = []\n",
        "  for i in range(len(loi_normale)):\n",
        "    loi_normale[i] = numpy.array(loi_normale[i])[0]\n",
        "    if loi_normale[i] >= limite:\n",
        "      normale_tronquee.append(loi_normale[i])\n",
        "  return random.choices(normale_tronquee)[0]"
      ],
      "metadata": {
        "id": "P6ZuLZir7fAt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duree_deplacement(list_coord_depart, list_coord_arrivee, time_):\n",
        "  \"\"\" Retourne la duree d'un trajet en secondes\n",
        "  Prend en entrée les coordonnées des points de départ et d'arrivée ainsi que l'heure :\n",
        "  ([x_depart,y_depart],[x_arrivee,y_arrivee],time) \"\"\"\n",
        "\n",
        "  distance = dist_manhattan(list_coord_depart, list_coord_arrivee)\n",
        "  depart = numpy.array(list_coord_depart)\n",
        "  arrivee = numpy.array(list_coord_arrivee)\n",
        "  zone_depart = env.xy_to_zone(depart)\n",
        "  zone_arrivee = env.xy_to_zone(arrivee)\n",
        "  tranche_horaire = int(time_/15/60)*15\n",
        "  vitesse_moyenne = speeds_data[(speeds_data['puzone']==zone_depart) & (speeds_data['dozone']==zone_arrivee) & (speeds_data['min']==tranche_horaire)]['speed_mean']\n",
        "  sigma = speeds_data[(speeds_data['puzone']==zone_depart) & (speeds_data['dozone']==zone_arrivee) & (speeds_data['min']==tranche_horaire)]['speed_stddev']\n",
        "  #vitesse_associee = vitesse_normalisee(vitesse_moyenne, sigma) #WAY TO MUCH TIME TO PROCESS\n",
        "  temps = distance/vitesse_moyenne\n",
        "  return numpy.array(temps)"
      ],
      "metadata": {
        "id": "U0cMbRNH7hIv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_to_request(car_coord, req_coord, car_job, time, first_job_coord, second_job_coord, third_job_coord):\n",
        "  \"\"\"\n",
        "  Return the distance to a request taking into account the jobs of the cars.\n",
        "  \"\"\"\n",
        "  car_job = str(car_job[0]) + str(car_job[1]) + str(car_job[2])\n",
        "  if car_job in ['044','444','104']: #Mistake 104\n",
        "    return duree_deplacement(car_coord,req_coord,time)\n",
        "  if car_job in ['344']:\n",
        "    return duree_deplacement(car_coord,first_job_coord[0],time) + duree_deplacement(first_job_coord[0],first_job_coord[1],time) + duree_deplacement(first_job_coord[1],req_coord,time)\n",
        "  if car_job == '234':\n",
        "    return duree_deplacement(car_coord,first_job_coord[0],time) + duree_deplacement(first_job_coord[0],first_job_coord[1],time) + duree_deplacement(first_job_coord[1],second_job_coord[0],time) + duree_deplacement(second_job_coord[0],second_job_coord[1],time) + duree_deplacement(second_job_coord[1],req_coord,time)\n",
        "  return duree_deplacement(car_coord,first_job_coord[0],time) + duree_deplacement(first_job_coord[0],first_job_coord[1],time) + duree_deplacement(first_job_coord[1],second_job_coord[0],time) + duree_deplacement(second_job_coord[0],second_job_coord[1],time) + duree_deplacement(second_job_coord[1],third_job_coord[0],time) + duree_deplacement(third_job_coord[0],third_job_coord[1],time) + duree_deplacement(third_job_coord[0],req_coord,time)"
      ],
      "metadata": {
        "id": "fYS9VNmLQ3UE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heuristic functions"
      ],
      "metadata": {
        "id": "hbSmoP09Jofr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def triplets_jobs(state):\n",
        "  \"\"\" Prend en entrée l'état de l'environnement et retourne les listes des indices des véhicules pour chaque\n",
        "  triplet de jobs sous forme d'une liste de listes ayant chaucune le triplet en premier élément \n",
        "  \"\"\"\n",
        "  jobs = state['v_jobs']\n",
        "  dic = {'044':[],'104':[],'234':[],'323':[],'344':[],'444':[]}\n",
        "  for i in range(len(jobs)):\n",
        "    triplet = str(jobs[i][0]) + str(jobs[i][1]) + str(jobs[i][2])\n",
        "    dic[triplet] += [i]\n",
        "  return dic"
      ],
      "metadata": {
        "id": "2yl4W71FJ14L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plus_proche_lot(coords_voiture, time):\n",
        "  \"\"\" Retourne l'indice du lot le plus proche, prend en entrée la liste des coordonnées du véhicule d'intérêt\n",
        "  [x,y] et l'heure \n",
        "  \"\"\"\n",
        "  lots = numpy.array(env.lots)\n",
        "  durees = []\n",
        "  for i in range(len(lots)):\n",
        "    durees.append(duree_deplacement(coords_voiture, lots[i], time)[0])\n",
        "  return np.argmin(durees)"
      ],
      "metadata": {
        "id": "7TknLUQ1J3FQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic(state):\n",
        "  \"\"\"\n",
        "  Returns the reposition according to the heuristic used.\n",
        "  \"\"\"\n",
        "  triplets = triplets_jobs(state)\n",
        "  reposition = [env.num_lots]*env.num_vehicles \n",
        "  if len(triplets['444']) > 0:\n",
        "    for i in range(len(triplets['444'])):\n",
        "      lot = plus_proche_lot(state['v_locs'][triplets['444'][i]], state['time'])\n",
        "      reposition[triplets['444'][i]] = lot\n",
        "  return np.array(reposition) #Créer l'array direct : improve"
      ],
      "metadata": {
        "id": "7bij2Yk_J5Ed"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q learning algorithm"
      ],
      "metadata": {
        "id": "XCDN3XuWKx1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size, device):\n",
        "        self.max_size = max_size\n",
        "        self.mem_cntr = 0\n",
        "\n",
        "        self.state_x_memory = [] #It stores the 'x' input\n",
        "        self.state_y_memory = [] #It stores the 'y' input\n",
        "        self.new_state_x_memory = [] \n",
        "        self.new_state_y_memory = []\n",
        "        self.action_memory = [] #Consider action going from 0 to nb_car // Size : self.mem_size*nb_actions_to_make_in_state(it varies)\n",
        "\n",
        "        self.terminal_memory = [] #We could use arrays here\n",
        "        self.reward_memory = [] #We could use arrays here\n",
        "        self.device = device\n",
        "\n",
        "    def push(self, state_x, state_y, action, reward, new_state_x, new_state_y, done):\n",
        "        \"\"\"\n",
        "        Add a new sample and replace oldest one if full\n",
        "        \"\"\"\n",
        "        self.state_x_memory += [state_x]\n",
        "        self.state_y_memory += [state_y]\n",
        "        self.new_state_x_memory += [new_state_x]\n",
        "        self.new_state_y_memory += [new_state_y]\n",
        "        self.action_memory += [action]\n",
        "        self.reward_memory += [reward]\n",
        "        self.terminal_memory += [done]\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "        # Supress 1st element if too many of them.\n",
        "        if self.mem_cntr>self.max_size:\n",
        "          self.state_x_memory.pop(0)\n",
        "          self.state_y_memory.pop(0)\n",
        "          self.new_state_x_memory.pop(0)\n",
        "          self.new_state_y_memory.pop(0)\n",
        "          self.action_memory.pop(0)\n",
        "          self.reward_memory.pop(0)\n",
        "          self.terminal_memory.pop(0)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"\n",
        "        Sample from the memory\n",
        "        return : list of size 'batch_size' containing different observations.\n",
        "        \"\"\"\n",
        "        max_mem = min(self.mem_cntr, self.max_size)\n",
        "        batch = np.random.choice(max_mem, batch_size, replace=False) #It's probably not gonna work that way.\n",
        "\n",
        "        states_x = []\n",
        "        states_y = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        new_states_x = []\n",
        "        new_states_y = []\n",
        "        terminal = []\n",
        "        for ele in batch:\n",
        "          states_x += [self.state_x_memory[ele]]\n",
        "          states_y += [self.state_y_memory[ele]]\n",
        "          actions += [self.action_memory[ele]]\n",
        "          rewards += [self.reward_memory[ele]]\n",
        "          new_states_x += [self.new_state_x_memory[ele]]\n",
        "          new_states_y += [self.new_state_y_memory[ele]]\n",
        "          terminal += [self.terminal_memory[ele]]\n",
        "\n",
        "        return states_x, states_y, actions, self.to_torch(rewards), new_states_x, new_states_y, self.to_torch(terminal)\n",
        "\n",
        "    def to_torch(self, x):\n",
        "        return torch.tensor(x).to(self.device)\n",
        "\n",
        "    def to_numpy(self, x):\n",
        "        return x.detach().cpu().numpy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(self.mem_cntr, self.max_size) "
      ],
      "metadata": {
        "id": "4trOxLIjAsBq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Network\n",
        "\n",
        "class ReqN(nn.Module):\n",
        "    def __init__(self, x_input_size, y_input_size, nb_car, hidden_size_1=10,hidden_size_2=500):\n",
        "        super().__init__()\n",
        "        self.x_input = x_input_size\n",
        "        self.y_input = y_input_size\n",
        "        self.nb_car = nb_car\n",
        "        self.linear_1 = nn.Linear(x_input_size, hidden_size_1)\n",
        "        self.linear_2 = nn.Linear(hidden_size_1, hidden_size_1)\n",
        "        self.linear_3 = nn.Linear(hidden_size_1*nb_car+y_input_size, hidden_size_2)\n",
        "        self.linear_4 = nn.Linear(hidden_size_2, hidden_size_2)\n",
        "        self.linear_5 = nn.Linear(hidden_size_2, nb_car+1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, y): #x : batch_size*(Nb_car)*x_input  ; y : batch_size*(nb_caracteristics_global : y_input)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        x = torch.cat((x,y),1)\n",
        "\n",
        "        x = self.linear_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear_4(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        output = self.linear_5(x)\n",
        "        if output.shape[0]==1:\n",
        "          x = x.squeeze(0)\n",
        "        return output"
      ],
      "metadata": {
        "id": "WmPDryyPBTy9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5JZUsQBYus"
      },
      "source": [
        "# Agent\n",
        "\n",
        "class Agent(object):\n",
        "\n",
        "    def __init__(self, \n",
        "                 n_actions,\n",
        "                 memory, \n",
        "                 eps, eps_decay,\n",
        "                 discount_rate, \n",
        "                 update_delay, \n",
        "                 device\n",
        "                 ):\n",
        "        \n",
        "        self.action_space = [i for i in range(n_actions)] # n_actions = nb of cars + 1\n",
        "        self.memory = memory \n",
        "        self.eps, self.eps_decay = eps, eps_decay\n",
        "        self.discount_rate = discount_rate\n",
        "        self.update_delay = update_delay\n",
        "        self.counter = 0\n",
        "        self.device = device\n",
        "\n",
        "    def init_nets(self, Q_net, target_net, optimizer, batch_size):\n",
        "        \"\"\"\n",
        "        initialize online and targets\n",
        "        \"\"\"\n",
        "        self.Q_net = Q_net\n",
        "        self.target_net = target_net\n",
        "        self.optimizer = optimizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.x_input = self.Q_net.x_input\n",
        "        self.y_input = self.Q_net.y_input\n",
        "        self.nb_car = self.Q_net.nb_car\n",
        "\n",
        "        self.copy_weights()\n",
        "        self.counter += 1\n",
        "    \n",
        "    def to_torch(self, x):\n",
        "        return torch.tensor(x).to(self.device).float()\n",
        "\n",
        "    def to_numpy(self, x):\n",
        "        return x.detach().cpu().numpy()\n",
        "\n",
        "    def create_mask(self,jobs,state,state_tensor_x,time_max=180): \n",
        "      \"\"\"\n",
        "      Create a mask for the car that we cannot assign to a certain request and that for every request of a state.\n",
        "      return: a list of 0 and 1 where 1 means that we mask the outcome, size: nb_request*(nb_car+1)\n",
        "      \"\"\"\n",
        "      # Deal with cars, for which the distance is too high.\n",
        "      nb_request = state_tensor_x.shape[0]\n",
        "      time = state['time']\n",
        "      mask = torch.zeros(nb_request,self.nb_car+1).to(self.device)\n",
        "      for i in range(nb_request):\n",
        "        request_time = state['request_times'][i]\n",
        "        for j in range(self.nb_car):\n",
        "          mask[i][j] = (time_max - state_tensor_x[i][j][2] + request_time - time) < 0 #if not accesible then 1.\n",
        "\n",
        "      # Deal with cars which already have too many jobs\n",
        "      for car in (jobs['323']+jobs['234']):\n",
        "        for i in range(nb_request):\n",
        "          mask[i,car] = 1 \n",
        "      return mask\n",
        "\n",
        "    def forward(self, states_x, states_y, targets, mask, list_association):\n",
        "        \"\"\"\n",
        "        Train online net for 1 step\n",
        "        \"\"\"\n",
        "        self.optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        self.Q_net.train()\n",
        "        Q_values = self.Q_net(states_x,states_y).to(device)\n",
        "\n",
        "        # Masking\n",
        "        Q_values = (Q_values*mask).sum(-1)\n",
        "\n",
        "        # Aggregate\n",
        "        Q_values = self.aggregation(Q_values,list_association)\n",
        "\n",
        "        # Computing loss\n",
        "        loss = (targets.detach() - Q_values).pow(2).mean()\n",
        "        loss.backward()\n",
        "\n",
        "        # Apply gradients\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.Q_net.eval()\n",
        "\n",
        "    def copy_weights(self):\n",
        "        \"\"\"\n",
        "        Copy weights from online to target net\n",
        "        \"\"\"\n",
        "        self.target_net.load_state_dict(self.Q_net.state_dict())\n",
        "\n",
        "    def select_action(self, states_x, states_y, mask): # Optimize it by taking the action : no assignement (in the beggining) very frequently.\n",
        "        \"\"\"\n",
        "        Select an action with eps greedy as well as dealing with the overlapping issue\n",
        "        \"\"\"\n",
        "        # Epsilon greedy\n",
        "\n",
        "        list_action = []\n",
        "        for i,(state_x,state_y) in enumerate(zip(states_x,states_y)):\n",
        "          rand = np.random.random()\n",
        "          if rand < self.eps: #If we choose randomly\n",
        "            action = np.random.choice(self.action_space)\n",
        "            while (action in list_action or mask[i][action]==1) and action != self.nb_car: #Continue until we find an action we can realize. #To improve\n",
        "              action = np.random.choice(self.action_space)\n",
        "            list_action += [action]\n",
        "          else: #If we take the max Q value\n",
        "            tensor_action = self.Q_net(state_x.unsqueeze(0),state_y.unsqueeze(0)).to(self.device)\n",
        "            tensor_action += tensor_action*mask[i]*(-100000) #We mask the actions we cannot take/ To improve\n",
        "            action = self.to_numpy(torch.max(tensor_action,1)[1])[0]\n",
        "            # Deal with overlapping actions : 1st arrived 1st served.\n",
        "            k = 2\n",
        "            while (action.item() in list_action or mask[i,action]==1) and action.item() != self.nb_car: #Continue until we find an action we can realize.\n",
        "              action = self.to_numpy(torch.topk(tensor_action.squeeze(0),k)[1][k-1])\n",
        "              k += 1\n",
        "            list_action += [action]\n",
        "                                          \n",
        "        return np.array(list_action) #To improve: we don't need to create a list\n",
        "\n",
        "    def remember(self, *args):\n",
        "        \"\"\"\n",
        "        Update memory\n",
        "        args: state_x, state_y, action, reward, new_state_x, new_state_y, done\n",
        "        \"\"\"\n",
        "\n",
        "        self.memory.push(*args)\n",
        "\n",
        "    def regroup_tensor(self, states_x, states_y):\n",
        "      \"\"\"\n",
        "      Regroup tensors into a unique tensor\n",
        "      return : a unique tensor composed of every input tensors with a list which associates the input with the output\n",
        "      \"\"\"\n",
        "      # Create an association list between the elements of this batch and compute the total amount of request in this batch.\n",
        "      n_element = 0\n",
        "      list_association = []\n",
        "\n",
        "      for i,(state_x,state_y) in enumerate(zip(states_x,states_y)):\n",
        "        n_element += len(state_x)\n",
        "        for j in range(len(state_x)):\n",
        "          list_association += [[i,j]]\n",
        "      \n",
        "      # Fill the tensors we're going to use for the batch\n",
        "      states_x_ = torch.zeros(n_element,self.nb_car,self.x_input).to(device)\n",
        "      states_y_ = torch.zeros(n_element,self.y_input).to(device)\n",
        "\n",
        "      count = 0\n",
        "      for i,(state_x,state_y) in enumerate(zip(states_x,states_y)):\n",
        "        for j in range(len(state_x)):\n",
        "          states_x_[count] = state_x[j]\n",
        "          states_y_[count] = state_y[j]\n",
        "          count += 1\n",
        "\n",
        "      return states_x_,states_y_,list_association\n",
        "\n",
        "    def dict_to_network(self,state):\n",
        "      \"\"\"\n",
        "      Takes (in input) the state dict and transforms it into a tensor while selecting the right features.\n",
        "      \"\"\"\n",
        "      # Build tensors x and y.\n",
        "      n = len(state['request_times'])\n",
        "      x_input = torch.zeros(n,self.nb_car,self.x_input).to(self.device)\n",
        "      y_input = torch.zeros(n,self.y_input).to(self.device)\n",
        "      for i in range(n):\n",
        "        for car in range(self.nb_car):\n",
        "          x_input[i][car][0] = state['v_locs'][car][0]\n",
        "          x_input[i][car][1] = state['v_locs'][car][1]\n",
        "          # Calculate the distance to the request.\n",
        "          first_job_coord = state['v_job_locs'][car][0] #We retrieve it even if it's not necessary\n",
        "          second_job_coord = state['v_job_locs'][car][1] \n",
        "          third_job_coord = state['v_job_locs'][car][2]\n",
        "          x_input[i][car][2] = self.to_torch(distance_to_request(state['v_locs'][car], state['request_locs'][i][0], state['v_jobs'][car], state['time'], first_job_coord, second_job_coord, third_job_coord))\n",
        "        y_input[i][0] = state['dow']\n",
        "        y_input[i][1] = state['time']\n",
        "        y_input[i][2] = state['request_times'][i]\n",
        "\n",
        "      return x_input,y_input\n",
        "\n",
        "    def action_to_tensor(self, actions):\n",
        "      \"\"\"\n",
        "      Transforms the list of actions of a batch into a single tensor.\n",
        "      \"\"\"\n",
        "      list_res = []\n",
        "      for list_action in actions:\n",
        "        for action in list_action:\n",
        "          list_res += [action]\n",
        "      return self.to_torch(np.array(list_res))\n",
        "    \n",
        "    def aggregation(self, Q_values, list_association): #Verified!\n",
        "      \"\"\"\n",
        "      Aggregate the Q_values for the request sharing the same timestep using the mean.\n",
        "      \"\"\"\n",
        "      # Filling tensors doing a double iteration\n",
        "      Agglomerate_Q_value = torch.zeros(self.batch_size,requires_grad=True).to(device)\n",
        "      current_batch = 0 #goes from 0 to batch_size\n",
        "      current_values = []\n",
        "      for i in range(len(Q_values)):\n",
        "        if list_association[i][0] == current_batch:\n",
        "          current_values += [Q_values[i].item()]\n",
        "        else:\n",
        "          Agglomerate_Q_value[current_batch] = np.mean(current_values)\n",
        "          current_batch += 1\n",
        "          current_values = [Q_values[i].item()]\n",
        "\n",
        "      return Agglomerate_Q_value\n",
        "\n",
        "\n",
        "    def policy(self):\n",
        "        \"\"\"\n",
        "        Apply deep Q-learning algorithm step\n",
        "        \"\"\"\n",
        "        if len(self.memory) >= self.batch_size:\n",
        "\n",
        "            # Sample from memory\n",
        "            states_x, states_y, actions, reward, new_states_x, new_states_y, done = self.memory.sample(self.batch_size) #Gotta have a reward per second probably\n",
        "\n",
        "            # Regroup the states and compute the association lists\n",
        "            states_x, states_y, list_association = self.regroup_tensor(states_x, states_y)\n",
        "            new_states_x, new_states_y, new_list_association = self.regroup_tensor(new_states_x, new_states_y)\n",
        "\n",
        "            # Compute target Q value\n",
        "            target_Q_value = self.target_net(new_states_x,new_states_y)\n",
        "\n",
        "            # Get action with highest Q_value\n",
        "            highest_Q_value = torch.max(target_Q_value, dim=-1)[0] #We should also here deal with the overlapping issue but it's not that important!!\n",
        "\n",
        "            # Agglomerate the different Q_value\n",
        "            Agglomerate_Q_value = self.aggregation(highest_Q_value,new_list_association)\n",
        "\n",
        "            # Compute target\n",
        "            target_Q_value = reward + self.discount_rate*Agglomerate_Q_value*done #The reward is a (mean reward (t)) #Discount rate(t('times')) #Verify that it's correct\n",
        "\n",
        "            # Change actions into usable tensors\n",
        "            actions = self.action_to_tensor(actions)\n",
        "\n",
        "            # Compute mask for non optimal actions\n",
        "            mask = F.one_hot(actions.long())\n",
        "\n",
        "            # Train network         \n",
        "            self.forward(states_x, states_y, target_Q_value, mask, list_association)\n",
        "\n",
        "            # Copy weights\n",
        "            if self.counter % self.update_delay == 0:\n",
        "                self.copy_weights()\n",
        "\n",
        "            # Update epsilon\n",
        "            self.eps *= self.eps_decay\n",
        "\n",
        "            self.counter += 1\n",
        "        else:\n",
        "            return\n",
        "        \n",
        "    "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "env = RidehailEnv()\n",
        "\n",
        "MEMORY_SIZE = 4000\n",
        "X_INPUT_SIZE = 3\n",
        "Y_INPUT_SIZE = 3\n",
        "N_CAR = env.num_vehicles\n",
        "\n",
        "LR = 0.001\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "N_SIMULATION = 10\n",
        "EPS = 0.3\n",
        "EPS_DECAY = 0.9995\n",
        "DISCOUNT_RATE = 0.99 # should depend of t\n",
        "UPDATE_DELAY = 50 # delay between target_net parameters updates\n",
        "DEVICE = \"cuda\" # \"cuda\" or \"cpu\"\n",
        "\n",
        "# Model and target model \n",
        "Q_net = ReqN(X_INPUT_SIZE, Y_INPUT_SIZE, N_CAR).to(DEVICE)\n",
        "target_net = ReqN(X_INPUT_SIZE, Y_INPUT_SIZE, N_CAR).to(DEVICE)\n",
        "\n",
        "# Optimizer (only on Q_net)\n",
        "optimizer = torch.optim.Adam(Q_net.parameters(), lr=LR)\n",
        "\n",
        "# Memory\n",
        "memory = ReplayBuffer(MEMORY_SIZE, DEVICE)\n",
        "\n",
        "# Agent and initialization\n",
        "agent = Agent(n_actions=N_CAR+1, \n",
        "              memory=memory, \n",
        "              eps=EPS, \n",
        "              eps_decay=EPS_DECAY,\n",
        "              discount_rate=DISCOUNT_RATE,\n",
        "              update_delay=UPDATE_DELAY, \n",
        "              device=DEVICE\n",
        "              )\n",
        "\n",
        "agent.init_nets(Q_net, target_net, optimizer, BATCH_SIZE)\n",
        "\n",
        "all_scores = []\n",
        "# Progress bar\n",
        "with tqdm.tqdm(total=N_SIMULATION, position=0, leave=True) as pbar:\n",
        "    for i in range(N_SIMULATION):\n",
        "        done = False\n",
        "        score = 0\n",
        "        # Reset env\n",
        "        state = env.reset()\n",
        "\n",
        "        # Make sure that the first state is a state with request\n",
        "        while len(state['request_times']) == 0:\n",
        "          action_rep = heuristic(new_state)\n",
        "          action = {'reposition': action_rep, 'req_assgts': np.array([]), 'req_rejections': np.array([])}\n",
        "          state, reward, _, _ = env.step(action)\n",
        "          score += reward\n",
        "\n",
        "        #Store the states in a list for the analysis.\n",
        "        list_state = []\n",
        "        list_state += [state]\n",
        "        state_tensor_x,state_tensor_y = agent.dict_to_network(state)\n",
        "        while not done:\n",
        "            print('Running...')\n",
        "            # Retrieve lists of triplets from state\n",
        "            jobs = triplets_jobs(state)\n",
        "\n",
        "            # Create the mask for every request (taking into account the distance)\n",
        "            mask = agent.create_mask(jobs,state,state_tensor_x)\n",
        "\n",
        "            # Apply Heuristic\n",
        "            action_rep = heuristic(state)\n",
        "\n",
        "            # Select action\n",
        "            action_req = agent.select_action(state_tensor_x,state_tensor_y, mask)\n",
        "\n",
        "            # Construct action # A not so probable error to correct : if request assign at the same time that a reposition is requested : gotta change the status!!!\n",
        "            action = OrderedDict({'reposition': action_rep, 'req_assgts': action_req, 'req_rejections': np.zeros_like(action_req)}) #Need to deal with the rejections probably #May need to be an ordered dict\n",
        "\n",
        "            print('Action:', action)\n",
        "            day = state['dow']\n",
        "            time = state['time']\n",
        "            print(f'day : {day}/ time : {time}')\n",
        "            # Execute action\n",
        "            new_state, reward, done, _ = env.step(action) #Should compute the mean reward.\n",
        "              \n",
        "            # While no request for new_state : Apply heuristic and create a new action / There may be a problem with done.\n",
        "            while len(new_state['request_times']) == 0:\n",
        "              action_rep = heuristic(new_state)\n",
        "              action = {'reposition': action_rep, 'req_assgts': np.array([]), 'req_rejections': np.array([])}\n",
        "              new_state, reward_add, done, _ = env.step(action)\n",
        "              reward += reward_add\n",
        "              \n",
        "            score += reward\n",
        "\n",
        "            # Transforms state into a usable tensor for the : request network\n",
        "            new_state_tensor_x,new_state_tensor_y = agent.dict_to_network(new_state)\n",
        "\n",
        "            # Update memory\n",
        "            agent.remember(state_tensor_x,state_tensor_y, action_req, reward, new_state_tensor_x, new_state_tensor_y, 1-int(done))\n",
        "\n",
        "            # Apply algorithm\n",
        "            agent.policy() #We should maybe iterate do apply the policy more often.\n",
        "\n",
        "            # Update state\n",
        "            state = new_state\n",
        "            list_state += [state]\n",
        "            state_tensor_x,state_tensor_y = new_state_tensor_x,new_state_tensor_y\n",
        "        \n",
        "        all_scores.append(score)\n",
        "\n",
        "        pbar.set_description('score=' + str(score))\n",
        "        pbar.update()\n",
        "\n",
        "plt.plot(all_scores)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6a7rW79NdLqT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afcd4995-106a-453d-89f9-57fe2df654f5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([15])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 224.29111309871996\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([7])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 484.9911660731291\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([6])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 488.7343229001261\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 1164.855381674763\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 1286.1023087517056\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302,  22, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 1555.8368161140995\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([16])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 2275.854765532202\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([13])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 2512.2328245689782\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([2])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3310.4169614442076\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3609.5891172410124\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([15, 19])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 3615.6367384728255\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 3943.576221714786\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([14])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 4303.121605854023\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 4768.66515640354\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([13])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 5447.141271005511\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 5687.833608211517\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 5851.6870929914385\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 7035.825492758854\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 16])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 7252.508285530079\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 7401.4466988465565\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 117, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 7546.347193378992\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([7])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 8056.1515212802215\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([2])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 8247.222540989042\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 9038.815113823015\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 9773.632299784724\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([10])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 11206.906657076785\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([4])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 11710.880263724146\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 11912.726813210715\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 181, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 12091.930051111365\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([16])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 12381.883272930681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Ignoring infeasible assignments for the following vehicles:\n",
            "Int64Index([3], dtype='int64').\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([3])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 12414.237043307852\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302,  74, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([2])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 12507.565554896144\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([3])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 12761.008963609343\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 12894.83140318488\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 13129.810911435166\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 298, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 13200.41624002746\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([1])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 13488.94768098116\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 13717.52853898413\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 14467.234552280821\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 14513.989981186754\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20, 18])), ('req_rejections', array([0, 0, 0]))])\n",
            "day : 4/ time : 14518.300873982791\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 137, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 14619.378734393797\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20, 20])), ('req_rejections', array([0, 0, 0]))])\n",
            "day : 4/ time : 14687.912113757524\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([1])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 15352.202214826908\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([16])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 15419.01384543237\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 15679.008872863245\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 20])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 15748.731459573512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Ignoring infeasible assignments for the following vehicles:\n",
            "Int64Index([10], dtype='int64').\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([10])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 16575.673424412063\n",
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302,  18, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])\n",
            "day : 4/ time : 16689.56087295142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [01:08<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n",
            "Action: OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
            "       302, 302, 302, 302, 302, 302, 302])), ('req_assgts', array([20, 17])), ('req_rejections', array([0, 0]))])\n",
            "day : 4/ time : 16735.746143822773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-4da38cefbe5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'day : {day}/ time : {time}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# Execute action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Should compute the mean reward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# While no request for new_state : Apply heuristic and create a new action / There may be a problem with done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyhailing/ridehail_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m## Phase I.I.a) Updating the vehicles' df for the service of the new requests.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_servers_job_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massgd_reqs_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m## Phase I.I.b) Updating the requests df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyhailing/ridehail_env.py\u001b[0m in \u001b[0;36m_update_servers_job_cols\u001b[0;34m(self, req_idxs, v_idxs)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;31m# Filling in a third null job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_null_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnow_servers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyhailing/ridehail_env.py\u001b[0m in \u001b[0;36m_make_null_jobs\u001b[0;34m(self, mask, jobs)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"j{n}{od}t\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vehicles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxcols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NULL_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vehicles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mycols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NULL_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vehicles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NEVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 \u001b[0;31m# scalar value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                     \u001b[0misetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36misetter\u001b[0;34m(loc, v)\u001b[0m\n\u001b[1;32m   1686\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                     \u001b[0;31m# set the item, possibly having a dtype change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m                     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m                     \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplane_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                     \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5663\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5664\u001b[0m         \"\"\"\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     def replace(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block_same_class\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "CBCsgdl6vcku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_RCaI-xnvvY",
        "outputId": "1d82600b-d9ef-42af-f981-803ac8e7e65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2880.5767908354665"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()\n",
        "state['dow']"
      ],
      "metadata": {
        "id": "OllsBrBzmPYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = list_state[30]['v_locs'][1]\n",
        "v1 = list_state[30]['request_locs'][0][0]\n",
        "time = list_state[30]['time']\n",
        "duree_deplacement(v,v1,time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTHpEC9Kbiwi",
        "outputId": "ce6c873a-3919-4686-df01-cd37d9c87cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([130.49006675])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_state[29]['request_times']"
      ],
      "metadata": {
        "id": "DtisxkIlc633"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_state[29]['v_jobs']"
      ],
      "metadata": {
        "id": "3WVzd84hcN_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_state[6]['v_jobs']"
      ],
      "metadata": {
        "id": "x37r_5Odb_Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = new_state['v_locs'][0]\n",
        "time = new_state['time']\n",
        "v1 = np.array(env.lots)[i]"
      ],
      "metadata": {
        "id": "YeVrJhkETcgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1"
      ],
      "metadata": {
        "id": "fch1_98mTwu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heuristic(new_state)"
      ],
      "metadata": {
        "id": "CMIKe-lQRkqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action = env.get_random_action()\n",
        "action "
      ],
      "metadata": {
        "id": "t7h9kBcAZdtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OrderedDict([('reposition', array([302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302, 302,\n",
        "       302])), ('req_assgts', array([20])), ('req_rejections', array([0]))])"
      ],
      "metadata": {
        "id": "eWnpsWN8-N2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
